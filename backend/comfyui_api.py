# ============================================
# ComfyUI API ì—°ë™ ëª¨ë“ˆ
# AI ì´ë¯¸ì§€ ìƒì„± ìë™í™” (SDXL ëª¨ë¸ ê¸°ë°˜)
# ============================================

import json
import urllib.request
import urllib.parse
import time
import uuid
import os
import random
from pathlib import Path

# ComfyUI ì„œë²„ ì„¤ì •
COMFYUI_URL = "http://127.0.0.1:8188"
OUTPUT_DIR = Path("D:/AI_Tools/ComfyUI/output")


class ComfyUIClient:
    """ComfyUI API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, server_url: str = COMFYUI_URL):
        self.server_url = server_url
        self.client_id = str(uuid.uuid4())
    
    def is_server_running(self) -> bool:
        """ì„œë²„ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸"""
        try:
            urllib.request.urlopen(f"{self.server_url}/system_stats", timeout=5)
            return True
        except:
            return False
    
    def queue_prompt(self, prompt: dict) -> dict:
        """í”„ë¡¬í”„íŠ¸ë¥¼ íì— ì¶”ê°€"""
        data = json.dumps({"prompt": prompt, "client_id": self.client_id}).encode('utf-8')
        req = urllib.request.Request(f"{self.server_url}/prompt", data=data)
        req.add_header('Content-Type', 'application/json')
        
        with urllib.request.urlopen(req) as response:
            return json.loads(response.read())
    
    def get_history(self, prompt_id: str) -> dict:
        """í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ê²°ê³¼ ì¡°íšŒ"""
        with urllib.request.urlopen(f"{self.server_url}/history/{prompt_id}") as response:
            return json.loads(response.read())
    
    def get_image(self, filename: str, subfolder: str = "", folder_type: str = "output") -> bytes:
        """ìƒì„±ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        params = urllib.parse.urlencode({
            "filename": filename,
            "subfolder": subfolder,
            "type": folder_type
        })
        with urllib.request.urlopen(f"{self.server_url}/view?{params}") as response:
            return response.read()
    
    def wait_for_completion(self, prompt_id: str, timeout: int = 300) -> dict:
        """í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            history = self.get_history(prompt_id)
            
            if prompt_id in history:
                status = history[prompt_id].get('status', {})
                if status.get('completed', False) or 'outputs' in history[prompt_id]:
                    return history[prompt_id]
                if status.get('status_str') == 'error':
                    raise RuntimeError(f"ìƒì„± ì‹¤íŒ¨: {status.get('messages', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            time.sleep(1)
        
        raise TimeoutError(f"í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼: {timeout}ì´ˆ")
    
    def generate_image(self, workflow: dict, output_path: str = None) -> list:
        """
        ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥
        
        Args:
            workflow: ComfyUI ì›Œí¬í”Œë¡œìš° (API í˜•ì‹)
            output_path: ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        
        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        # í”„ë¡¬í”„íŠ¸ íì— ì¶”ê°€
        result = self.queue_prompt(workflow)
        prompt_id = result['prompt_id']
        print(f"ğŸš€ í”„ë¡¬í”„íŠ¸ ID: {prompt_id}")
        
        # ì™„ë£Œ ëŒ€ê¸°
        print("â³ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        history = self.wait_for_completion(prompt_id)
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ìˆ˜ì§‘
        output_images = []
        
        if 'outputs' in history:
            for node_id, node_output in history['outputs'].items():
                if 'images' in node_output:
                    for image_info in node_output['images']:
                        filename = image_info['filename']
                        subfolder = image_info.get('subfolder', '')
                        
                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                        image_data = self.get_image(filename, subfolder)
                        
                        # ì €ì¥ ê²½ë¡œ ì„¤ì •
                        if output_path:
                            save_path = Path(output_path)
                            save_path.parent.mkdir(parents=True, exist_ok=True)
                        else:
                            save_path = OUTPUT_DIR / filename
                        
                        # ì´ë¯¸ì§€ ì €ì¥
                        with open(save_path, 'wb') as f:
                            f.write(image_data)
                        
                        output_images.append(str(save_path))
                        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
        
        return output_images


# ============================================
# SDXL ì´ë¯¸ì§€ ìƒì„± ì›Œí¬í”Œë¡œìš°
# ============================================

def create_sdxl_workflow(
    prompt: str,
    negative_prompt: str = "blurry, low quality, distorted, ugly, bad anatomy, deformed, amateur, watermark, signature, text",
    width: int = 1024,
    height: int = 1024,
    steps: int = 35,
    cfg: float = 7.5,
    seed: int = -1,
    sampler: str = "dpmpp_2m_sde",
    scheduler: str = "karras"
) -> dict:
    """
    SDXL ì´ë¯¸ì§€ ìƒì„± ì›Œí¬í”Œë¡œìš°
    
    ì‚¬ìš© ëª¨ë¸:
    - checkpoints/sd_xl_base_1.0.safetensors
    
    Args:
        prompt: ìƒì„±í•  ì´ë¯¸ì§€ ì„¤ëª…
        negative_prompt: í”¼í•˜ê³  ì‹¶ì€ ìš”ì†Œ
        width: ì´ë¯¸ì§€ ë„ˆë¹„ (ê¶Œì¥: 1024)
        height: ì´ë¯¸ì§€ ë†’ì´ (ê¶Œì¥: 1024)
        steps: ìƒì„± ìŠ¤í… ìˆ˜ (20-30 ê¶Œì¥)
        cfg: CFG ìŠ¤ì¼€ì¼ (7.0-8.0 ê¶Œì¥)
        seed: ëœë¤ ì‹œë“œ (-1ì´ë©´ ìë™)
        sampler: ìƒ˜í”ŒëŸ¬ ì¢…ë¥˜
        scheduler: ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë¥˜
    """
    if seed == -1:
        seed = random.randint(0, 2**32 - 1)
    
    workflow = {
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (SDXL Base)
        "4": {
            "class_type": "CheckpointLoaderSimple",
            "inputs": {
                "ckpt_name": "sd_xl_base_1.0.safetensors"
            }
        },
        # ê¸ì • í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”©
        "6": {
            "class_type": "CLIPTextEncode",
            "inputs": {
                "clip": ["4", 1],
                "text": prompt
            }
        },
        # ë¶€ì • í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”©
        "7": {
            "class_type": "CLIPTextEncode",
            "inputs": {
                "clip": ["4", 1],
                "text": negative_prompt
            }
        },
        # ë¹ˆ Latent ì´ë¯¸ì§€
        "5": {
            "class_type": "EmptyLatentImage",
            "inputs": {
                "batch_size": 1,
                "height": height,
                "width": width
            }
        },
        # KSampler
        "3": {
            "class_type": "KSampler",
            "inputs": {
                "cfg": cfg,
                "denoise": 1.0,
                "latent_image": ["5", 0],
                "model": ["4", 0],
                "negative": ["7", 0],
                "positive": ["6", 0],
                "sampler_name": sampler,
                "scheduler": scheduler,
                "seed": seed,
                "steps": steps
            }
        },
        # VAE ë””ì½”ë“œ
        "8": {
            "class_type": "VAEDecode",
            "inputs": {
                "samples": ["3", 0],
                "vae": ["4", 2]
            }
        },
        # ì´ë¯¸ì§€ ì €ì¥
        "9": {
            "class_type": "SaveImage",
            "inputs": {
                "filename_prefix": "AIStudio",
                "images": ["8", 0]
            }
        }
    }
    
    return workflow


# ============================================
# FLUX.1 ì´ë¯¸ì§€ ìƒì„± ì›Œí¬í”Œë¡œìš° (ìµœê³  í’ˆì§ˆ)
# ============================================

def create_flux_workflow(
    prompt: str,
    width: int = 1024,
    height: int = 1024,
    steps: int = 4,
    guidance: float = 3.5,
    seed: int = -1
) -> dict:
    """
    FLUX.1-schnell ì´ë¯¸ì§€ ìƒì„± ì›Œí¬í”Œë¡œìš°
    
    FLUXëŠ” negative promptê°€ í•„ìš” ì—†ê³ , ì ì€ ìŠ¤í…ìœ¼ë¡œë„ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
    
    ì‚¬ìš© ëª¨ë¸:
    - unet/flux1-schnell-fp8.safetensors
    - clip/clip_l.safetensors
    - clip/t5xxl_fp8_e4m3fn.safetensors
    - vae/ae.safetensors
    
    Args:
        prompt: ìƒì„±í•  ì´ë¯¸ì§€ ì„¤ëª… (ìƒì„¸í• ìˆ˜ë¡ ì¢‹ìŒ)
        width: ì´ë¯¸ì§€ ë„ˆë¹„ (ê¶Œì¥: 1024)
        height: ì´ë¯¸ì§€ ë†’ì´ (ê¶Œì¥: 1024)
        steps: ìƒì„± ìŠ¤í… ìˆ˜ (schnellì€ 4ìŠ¤í… ê¶Œì¥)
        guidance: ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (3.5 ê¶Œì¥)
        seed: ëœë¤ ì‹œë“œ (-1ì´ë©´ ìë™)
    """
    if seed == -1:
        seed = random.randint(0, 2**32 - 1)
    
    workflow = {
        # UNET ë¡œë” (FLUX ëª¨ë¸)
        "10": {
            "class_type": "UNETLoader",
            "inputs": {
                "unet_name": "flux1-schnell-fp8.safetensors",
                "weight_dtype": "fp8_e4m3fn"
            }
        },
        # ë“€ì–¼ CLIP ë¡œë” (CLIP-L + T5-XXL)
        "11": {
            "class_type": "DualCLIPLoader",
            "inputs": {
                "clip_name1": "clip_l.safetensors",
                "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
                "type": "flux"
            }
        },
        # VAE ë¡œë”
        "12": {
            "class_type": "VAELoader",
            "inputs": {
                "vae_name": "ae.safetensors"
            }
        },
        # CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”© (FLUXìš©)
        "6": {
            "class_type": "CLIPTextEncode",
            "inputs": {
                "clip": ["11", 0],
                "text": prompt
            }
        },
        # ë¹ˆ SD3 Latent ì´ë¯¸ì§€ (FLUX í˜¸í™˜)
        "5": {
            "class_type": "EmptySD3LatentImage",
            "inputs": {
                "batch_size": 1,
                "height": height,
                "width": width
            }
        },
        # FluxGuidance (ê°€ì´ë˜ìŠ¤ ì„¤ì •)
        "13": {
            "class_type": "FluxGuidance",
            "inputs": {
                "conditioning": ["6", 0],
                "guidance": guidance
            }
        },
        # KSampler
        "3": {
            "class_type": "KSampler",
            "inputs": {
                "cfg": 1.0,
                "denoise": 1.0,
                "latent_image": ["5", 0],
                "model": ["10", 0],
                "negative": ["6", 0],
                "positive": ["13", 0],
                "sampler_name": "euler",
                "scheduler": "simple",
                "seed": seed,
                "steps": steps
            }
        },
        # VAE ë””ì½”ë“œ
        "8": {
            "class_type": "VAEDecode",
            "inputs": {
                "samples": ["3", 0],
                "vae": ["12", 0]
            }
        },
        # ì´ë¯¸ì§€ ì €ì¥
        "9": {
            "class_type": "SaveImage",
            "inputs": {
                "filename_prefix": "FLUX",
                "images": ["8", 0]
            }
        }
    }
    
    return workflow


# í˜„ì¬ ì‚¬ìš©í•  ëª¨ë¸ ì„¤ì • (FLUXê°€ ìˆìœ¼ë©´ FLUX ì‚¬ìš©, ì—†ìœ¼ë©´ SDXL)
USE_FLUX = True  # True: FLUX ì‚¬ìš©, False: SDXL ì‚¬ìš©


def get_available_model():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸"""
    flux_model = Path("D:/AI_Tools/ComfyUI/models/unet/flux1-schnell-fp8.safetensors")
    flux_clip = Path("D:/AI_Tools/ComfyUI/models/clip/t5xxl_fp8_e4m3fn.safetensors")
    
    if flux_model.exists() and flux_clip.exists():
        return "flux"
    return "sdxl"


# ============================================
# ì‚¬ì—…ìš© ê°„í¸ í•¨ìˆ˜
# ============================================

def generate_product_image(
    product_description: str,
    style: str = "professional product photography",
    background: str = "clean white background",
    output_path: str = None,
    width: int = 1024,
    height: int = 1024
) -> list:
    """
    ì œí’ˆ ì´ë¯¸ì§€ ìƒì„± (FLUX ë˜ëŠ” SDXL ìë™ ì„ íƒ)
    """
    model = get_available_model()
    client = ComfyUIClient()
    
    if model == "flux":
        # FLUXìš© í”„ë¡¬í”„íŠ¸ (ìì—°ì–´ ìŠ¤íƒ€ì¼, ë” ìƒì„¸í•˜ê²Œ)
        prompt = f"A professional commercial photograph of {product_description}. {style}, {background}. Shot with a high-end DSLR camera, perfect studio lighting, soft shadows, extremely sharp focus, 8K resolution, photorealistic, product photography for advertising campaign"
        
        workflow = create_flux_workflow(
            prompt=prompt,
            width=width,
            height=height,
            steps=4,
            guidance=3.5
        )
    else:
        # SDXLìš© í”„ë¡¬í”„íŠ¸
        prompt = f"masterpiece, best quality, {product_description}, {style}, {background}, extremely detailed, photorealistic, 8k uhd, high resolution, commercial photography, professional studio lighting, sharp focus, ray tracing, global illumination, perfect shadows, award winning photography"
        negative = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, amateur, poorly lit, overexposed, underexposed, distorted, deformed, ugly, duplicate, morbid, mutilated, disfigured"
        
        workflow = create_sdxl_workflow(
            prompt=prompt,
            negative_prompt=negative,
            width=width,
            height=height,
            steps=40,
            cfg=7.0
        )
    
    return client.generate_image(workflow, output_path)


def generate_thumbnail(
    title: str,
    theme: str = "vibrant and eye-catching",
    output_path: str = None
) -> list:
    """
    ìœ íŠœë¸Œ ì¸ë„¤ì¼ìš© ì´ë¯¸ì§€ ìƒì„± (FLUX ë˜ëŠ” SDXL ìë™ ì„ íƒ)
    """
    model = get_available_model()
    client = ComfyUIClient()
    
    if model == "flux":
        prompt = f"A stunning YouTube thumbnail image about {title}. {theme} style, bold vivid colors, dramatic cinematic lighting, high contrast, eye-catching composition, professional digital art, vibrant, trending on artstation, 8K resolution, volumetric lighting, depth of field, visually striking"
        
        workflow = create_flux_workflow(
            prompt=prompt,
            width=1280,
            height=720,
            steps=4,
            guidance=3.5
        )
    else:
        prompt = f"masterpiece, best quality, {title}, {theme}, youtube thumbnail style, bold vivid colors, dramatic cinematic lighting, high contrast, ultra detailed, eye-catching composition, professional digital art, trending on artstation, 8k resolution, volumetric lighting, depth of field"
        negative = "lowres, blurry, boring, dull colors, low contrast, text, watermark, signature, worst quality, low quality, normal quality, jpeg artifacts, amateur, poorly composed, flat lighting"
        
        workflow = create_sdxl_workflow(
            prompt=prompt,
            negative_prompt=negative,
            width=1280,
            height=720,
            steps=35,
            cfg=7.5
        )
    
    return client.generate_image(workflow, output_path)


def generate_banner(
    concept: str,
    size: tuple = (1536, 512),
    output_path: str = None
) -> list:
    """
    ì›¹ ë°°ë„ˆ ì´ë¯¸ì§€ ìƒì„± (FLUX ë˜ëŠ” SDXL ìë™ ì„ íƒ)
    """
    model = get_available_model()
    client = ComfyUIClient()
    
    if model == "flux":
        prompt = f"A professional web banner design for {concept}. Modern minimalist style, clean layout, professional, sleek design, high quality, elegant, suitable for website header, 8K resolution"
        
        workflow = create_flux_workflow(
            prompt=prompt,
            width=size[0],
            height=size[1],
            steps=4,
            guidance=3.5
        )
    else:
        prompt = f"{concept}, web banner design, modern, clean, professional, minimalist, high quality, sleek"
        negative = "cluttered, busy, low quality, pixelated, text, watermark"
        
        workflow = create_sdxl_workflow(
            prompt=prompt,
            negative_prompt=negative,
            width=size[0],
            height=size[1],
            steps=25,
            cfg=7.5
        )
    
    return client.generate_image(workflow, output_path)


def generate_custom(
    prompt: str,
    negative_prompt: str = "lowres, bad anatomy, bad hands, text, error, missing fingers, cropped, worst quality, low quality, jpeg artifacts, signature, watermark, blurry, deformed, ugly",
    width: int = 1024,
    height: int = 1024,
    steps: int = 35,
    cfg: float = 7.0,
    output_path: str = None
) -> list:
    """
    ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„± (FLUX ë˜ëŠ” SDXL ìë™ ì„ íƒ)
    """
    model = get_available_model()
    client = ComfyUIClient()
    
    if model == "flux":
        # FLUXìš©: ìì—°ì–´ ìŠ¤íƒ€ì¼ë¡œ í”„ë¡¬í”„íŠ¸ ê°•í™”
        enhanced_prompt = f"{prompt}. Highly detailed, professional quality, 8K resolution, sharp focus, beautiful composition"
        
        workflow = create_flux_workflow(
            prompt=enhanced_prompt,
            width=width,
            height=height,
            steps=4,
            guidance=3.5
        )
    else:
        # SDXLìš©: í’ˆì§ˆ íƒœê·¸ ì¶”ê°€
        enhanced_prompt = f"masterpiece, best quality, highly detailed, {prompt}, 8k uhd, sharp focus, professional"
        enhanced_negative = f"{negative_prompt}, amateur, poorly drawn, bad proportions"
        
        workflow = create_sdxl_workflow(
            prompt=enhanced_prompt,
            negative_prompt=enhanced_negative,
            width=width,
            height=height,
            steps=steps,
            cfg=cfg
        )
    
    return client.generate_image(workflow, output_path)
    
    client = ComfyUIClient()
    return client.generate_image(workflow, output_path)


def batch_generate(
    prompts: list,
    output_dir: str = None,
    width: int = 1024,
    height: int = 1024
) -> list:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±
    
    Args:
        prompts: í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        width: ì´ë¯¸ì§€ ë„ˆë¹„
        height: ì´ë¯¸ì§€ ë†’ì´
    
    Returns:
        ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    client = ComfyUIClient()
    all_images = []
    
    for i, prompt in enumerate(prompts):
        print(f"\nğŸ“· ì´ë¯¸ì§€ {i+1}/{len(prompts)} ìƒì„± ì¤‘...")
        
        if output_dir:
            output_path = os.path.join(output_dir, f"image_{i+1:03d}.png")
        else:
            output_path = None
        
        workflow = create_sdxl_workflow(
            prompt=prompt,
            width=width,
            height=height,
            steps=25
        )
        
        images = client.generate_image(workflow, output_path)
        all_images.extend(images)
    
    return all_images


# ============================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================

if __name__ == "__main__":
    # ComfyUI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = ComfyUIClient()
    
    # ì„œë²„ ìƒíƒœ í™•ì¸
    if not client.is_server_running():
        print("âŒ ComfyUI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤!")
        print("   D:\\AI_Tools\\ComfyUI í´ë”ì—ì„œ run_nvidia_gpu.bat ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    print("âœ… ComfyUI ì„œë²„ ì—°ê²°ë¨")
    
    # ì˜ˆì‹œ: ì œí’ˆ ì´ë¯¸ì§€ ìƒì„±
    print("\nğŸ“¦ ì œí’ˆ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸...")
    try:
        images = generate_product_image(
            product_description="luxury perfume bottle with elegant gold accents and glass design",
            style="studio product photography, soft lighting, reflections",
            background="gradient gray background"
        )
        print(f"âœ… ìƒì„±ëœ ì´ë¯¸ì§€: {images}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
